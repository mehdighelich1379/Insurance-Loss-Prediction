{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Importing Required Libraries\n",
    "\n",
    "In this section, we import the necessary libraries for data handling, visualization, preprocessing, and building the deep learning model.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error  , r2_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Loading and Exploring the Dataset\n",
    "\n",
    "We load the dataset and check its structure. This helps us understand what kind of data we are working with.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont6     cont7  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B  ...  0.718367  0.335060   \n",
       "1   2    A    B    A    A    A    A    A    A    B  ...  0.438917  0.436585   \n",
       "2   5    A    B    A    A    B    A    A    A    B  ...  0.289648  0.315545   \n",
       "3  10    B    B    A    B    A    A    A    A    B  ...  0.440945  0.391128   \n",
       "4  11    A    B    A    B    A    A    A    A    B  ...  0.178193  0.247408   \n",
       "\n",
       "     cont8    cont9   cont10    cont11    cont12    cont13    cont14     loss  \n",
       "0  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493  0.714843  2213.18  \n",
       "1  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431  0.304496  1283.60  \n",
       "2  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709  0.774425  3005.09  \n",
       "3  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077  0.602642   939.85  \n",
       "4  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('train.csv')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we check the basic structure of the dataset and look for missing values or abnormal data.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188318 entries, 0 to 188317\n",
      "Columns: 132 entries, id to loss\n",
      "dtypes: float64(15), int64(1), object(116)\n",
      "memory usage: 189.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "cat1      0\n",
       "cat2      0\n",
       "cat3      0\n",
       "cat4      0\n",
       "         ..\n",
       "cont11    0\n",
       "cont12    0\n",
       "cont13    0\n",
       "cont14    0\n",
       "loss      0\n",
       "Length: 132, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "      <td>188318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>294135.982561</td>\n",
       "      <td>0.493861</td>\n",
       "      <td>0.507188</td>\n",
       "      <td>0.498918</td>\n",
       "      <td>0.491812</td>\n",
       "      <td>0.487428</td>\n",
       "      <td>0.490945</td>\n",
       "      <td>0.484970</td>\n",
       "      <td>0.486437</td>\n",
       "      <td>0.485506</td>\n",
       "      <td>0.498066</td>\n",
       "      <td>0.493511</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>0.493138</td>\n",
       "      <td>0.495717</td>\n",
       "      <td>3037.337686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>169336.084867</td>\n",
       "      <td>0.187640</td>\n",
       "      <td>0.207202</td>\n",
       "      <td>0.202105</td>\n",
       "      <td>0.211292</td>\n",
       "      <td>0.209027</td>\n",
       "      <td>0.205273</td>\n",
       "      <td>0.178450</td>\n",
       "      <td>0.199370</td>\n",
       "      <td>0.181660</td>\n",
       "      <td>0.185877</td>\n",
       "      <td>0.209737</td>\n",
       "      <td>0.209427</td>\n",
       "      <td>0.212777</td>\n",
       "      <td>0.222488</td>\n",
       "      <td>2904.086186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.176921</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>0.069503</td>\n",
       "      <td>0.236880</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035321</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.179722</td>\n",
       "      <td>0.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>147748.250000</td>\n",
       "      <td>0.346090</td>\n",
       "      <td>0.358319</td>\n",
       "      <td>0.336963</td>\n",
       "      <td>0.327354</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.336105</td>\n",
       "      <td>0.350175</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>0.358970</td>\n",
       "      <td>0.364580</td>\n",
       "      <td>0.310961</td>\n",
       "      <td>0.311661</td>\n",
       "      <td>0.315758</td>\n",
       "      <td>0.294610</td>\n",
       "      <td>1204.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>294539.500000</td>\n",
       "      <td>0.475784</td>\n",
       "      <td>0.555782</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.452887</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.438285</td>\n",
       "      <td>0.441060</td>\n",
       "      <td>0.441450</td>\n",
       "      <td>0.461190</td>\n",
       "      <td>0.457203</td>\n",
       "      <td>0.462286</td>\n",
       "      <td>0.363547</td>\n",
       "      <td>0.407403</td>\n",
       "      <td>2115.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>440680.500000</td>\n",
       "      <td>0.623912</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.634224</td>\n",
       "      <td>0.652072</td>\n",
       "      <td>0.643315</td>\n",
       "      <td>0.655021</td>\n",
       "      <td>0.591045</td>\n",
       "      <td>0.623580</td>\n",
       "      <td>0.566820</td>\n",
       "      <td>0.614590</td>\n",
       "      <td>0.678924</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.689974</td>\n",
       "      <td>0.724623</td>\n",
       "      <td>3864.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>587633.000000</td>\n",
       "      <td>0.984975</td>\n",
       "      <td>0.862654</td>\n",
       "      <td>0.944251</td>\n",
       "      <td>0.954297</td>\n",
       "      <td>0.983674</td>\n",
       "      <td>0.997162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980200</td>\n",
       "      <td>0.995400</td>\n",
       "      <td>0.994980</td>\n",
       "      <td>0.998742</td>\n",
       "      <td>0.998484</td>\n",
       "      <td>0.988494</td>\n",
       "      <td>0.844848</td>\n",
       "      <td>121012.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id          cont1          cont2          cont3  \\\n",
       "count  188318.000000  188318.000000  188318.000000  188318.000000   \n",
       "mean   294135.982561       0.493861       0.507188       0.498918   \n",
       "std    169336.084867       0.187640       0.207202       0.202105   \n",
       "min         1.000000       0.000016       0.001149       0.002634   \n",
       "25%    147748.250000       0.346090       0.358319       0.336963   \n",
       "50%    294539.500000       0.475784       0.555782       0.527991   \n",
       "75%    440680.500000       0.623912       0.681761       0.634224   \n",
       "max    587633.000000       0.984975       0.862654       0.944251   \n",
       "\n",
       "               cont4          cont5          cont6          cont7  \\\n",
       "count  188318.000000  188318.000000  188318.000000  188318.000000   \n",
       "mean        0.491812       0.487428       0.490945       0.484970   \n",
       "std         0.211292       0.209027       0.205273       0.178450   \n",
       "min         0.176921       0.281143       0.012683       0.069503   \n",
       "25%         0.327354       0.281143       0.336105       0.350175   \n",
       "50%         0.452887       0.422268       0.440945       0.438285   \n",
       "75%         0.652072       0.643315       0.655021       0.591045   \n",
       "max         0.954297       0.983674       0.997162       1.000000   \n",
       "\n",
       "               cont8          cont9         cont10         cont11  \\\n",
       "count  188318.000000  188318.000000  188318.000000  188318.000000   \n",
       "mean        0.486437       0.485506       0.498066       0.493511   \n",
       "std         0.199370       0.181660       0.185877       0.209737   \n",
       "min         0.236880       0.000080       0.000000       0.035321   \n",
       "25%         0.312800       0.358970       0.364580       0.310961   \n",
       "50%         0.441060       0.441450       0.461190       0.457203   \n",
       "75%         0.623580       0.566820       0.614590       0.678924   \n",
       "max         0.980200       0.995400       0.994980       0.998742   \n",
       "\n",
       "              cont12         cont13         cont14           loss  \n",
       "count  188318.000000  188318.000000  188318.000000  188318.000000  \n",
       "mean        0.493150       0.493138       0.495717    3037.337686  \n",
       "std         0.209427       0.212777       0.222488    2904.086186  \n",
       "min         0.036232       0.000228       0.179722       0.670000  \n",
       "25%         0.311661       0.315758       0.294610    1204.460000  \n",
       "50%         0.462286       0.363547       0.407403    2115.570000  \n",
       "75%         0.675759       0.689974       0.724623    3864.045000  \n",
       "max         0.998484       0.988494       0.844848  121012.250000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">cont and categorical patterns</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cont1',\n",
       " 'cont2',\n",
       " 'cont3',\n",
       " 'cont4',\n",
       " 'cont5',\n",
       " 'cont6',\n",
       " 'cont7',\n",
       " 'cont8',\n",
       " 'cont9',\n",
       " 'cont10',\n",
       " 'cont11',\n",
       " 'cont12',\n",
       " 'cont13',\n",
       " 'cont14']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pattern = re.compile('^cat([0-9]|[0-9][0-9]|[0-9][0-9][0-9])$')\n",
    "cont_pattern = re.compile('^cont([0-9]|[0-9][0-9]|[0-9][0-9][0-9])$')\n",
    "cat_columns = sorted([cat for cat in data_train.columns if 'cat' in cat] , key= lambda s : int(s[3:]))\n",
    "cont_columns = sorted([cont for cont in data_train.columns if 'cont' in cont] , key=lambda s: int(s[4:]))\n",
    "cat_columns\n",
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188313</th>\n",
       "      <td>587620</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242437</td>\n",
       "      <td>0.289949</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.30859</td>\n",
       "      <td>0.32935</td>\n",
       "      <td>0.223038</td>\n",
       "      <td>0.220003</td>\n",
       "      <td>0.333292</td>\n",
       "      <td>0.208216</td>\n",
       "      <td>1198.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188314</th>\n",
       "      <td>587624</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334270</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.63475</td>\n",
       "      <td>0.40455</td>\n",
       "      <td>0.47779</td>\n",
       "      <td>0.307628</td>\n",
       "      <td>0.301921</td>\n",
       "      <td>0.318646</td>\n",
       "      <td>0.305872</td>\n",
       "      <td>1108.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188315</th>\n",
       "      <td>587630</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345883</td>\n",
       "      <td>0.370534</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.45808</td>\n",
       "      <td>0.47779</td>\n",
       "      <td>0.445614</td>\n",
       "      <td>0.443374</td>\n",
       "      <td>0.339244</td>\n",
       "      <td>0.503888</td>\n",
       "      <td>5762.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188316</th>\n",
       "      <td>587632</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704364</td>\n",
       "      <td>0.562866</td>\n",
       "      <td>0.34987</td>\n",
       "      <td>0.44767</td>\n",
       "      <td>0.53881</td>\n",
       "      <td>0.863052</td>\n",
       "      <td>0.852865</td>\n",
       "      <td>0.654753</td>\n",
       "      <td>0.721707</td>\n",
       "      <td>1562.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188317</th>\n",
       "      <td>587633</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844563</td>\n",
       "      <td>0.533048</td>\n",
       "      <td>0.97123</td>\n",
       "      <td>0.93383</td>\n",
       "      <td>0.83814</td>\n",
       "      <td>0.932195</td>\n",
       "      <td>0.946432</td>\n",
       "      <td>0.810511</td>\n",
       "      <td>0.721460</td>\n",
       "      <td>4751.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188318 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont6  \\\n",
       "0            1    A    B    A    B    A    A    A    A    B  ...  0.718367   \n",
       "1            2    A    B    A    A    A    A    A    A    B  ...  0.438917   \n",
       "2            5    A    B    A    A    B    A    A    A    B  ...  0.289648   \n",
       "3           10    B    B    A    B    A    A    A    A    B  ...  0.440945   \n",
       "4           11    A    B    A    B    A    A    A    A    B  ...  0.178193   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "188313  587620    A    B    A    A    A    A    A    A    B  ...  0.242437   \n",
       "188314  587624    A    A    A    A    A    B    A    A    A  ...  0.334270   \n",
       "188315  587630    A    B    A    A    A    A    A    B    B  ...  0.345883   \n",
       "188316  587632    A    B    A    A    A    A    A    A    B  ...  0.704364   \n",
       "188317  587633    B    A    A    B    A    A    A    A    A  ...  0.844563   \n",
       "\n",
       "           cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0       0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1       0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2       0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "3       0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "4       0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "...          ...      ...      ...      ...       ...       ...       ...   \n",
       "188313  0.289949  0.24564  0.30859  0.32935  0.223038  0.220003  0.333292   \n",
       "188314  0.382000  0.63475  0.40455  0.47779  0.307628  0.301921  0.318646   \n",
       "188315  0.370534  0.24564  0.45808  0.47779  0.445614  0.443374  0.339244   \n",
       "188316  0.562866  0.34987  0.44767  0.53881  0.863052  0.852865  0.654753   \n",
       "188317  0.533048  0.97123  0.93383  0.83814  0.932195  0.946432  0.810511   \n",
       "\n",
       "          cont14     loss  \n",
       "0       0.714843  2213.18  \n",
       "1       0.304496  1283.60  \n",
       "2       0.774425  3005.09  \n",
       "3       0.602642   939.85  \n",
       "4       0.432606  2763.85  \n",
       "...          ...      ...  \n",
       "188313  0.208216  1198.62  \n",
       "188314  0.305872  1108.34  \n",
       "188315  0.503888  5762.64  \n",
       "188316  0.721707  1562.87  \n",
       "188317  0.721460  4751.72  \n",
       "\n",
       "[188318 rows x 132 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop id\n",
    "data_train.drop(columns=['id'] , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Splitting Data into Training and Testing Sets\n",
    "\n",
    "We split the dataset into training and testing sets using a fixed random seed for reproducibility.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_train.iloc[:,:-1]\n",
    "y = data_train.loss\n",
    "x_train , x_test , y_train , y_test = train_test_split(X , y , random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">find cat index</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_index = [i for i in range(0,len(data_train.columns)) if cat_pattern.match(data_train.columns[i])]\n",
    "cat_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(cat_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">1)catboost model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1926.5620867\ttest: 1918.2623619\tbest: 1918.2623619 (0)\ttotal: 128ms\tremaining: 38.1s\n",
      "1:\ttotal: 235ms\tremaining: 35s\n",
      "2:\ttotal: 340ms\tremaining: 33.7s\n",
      "3:\ttotal: 449ms\tremaining: 33.2s\n",
      "4:\ttotal: 550ms\tremaining: 32.4s\n",
      "5:\tlearn: 1757.2448208\ttest: 1751.2722175\tbest: 1751.2722175 (5)\ttotal: 652ms\tremaining: 32s\n",
      "6:\ttotal: 747ms\tremaining: 31.3s\n",
      "7:\ttotal: 849ms\tremaining: 31s\n",
      "8:\ttotal: 945ms\tremaining: 30.6s\n",
      "9:\ttotal: 1.05s\tremaining: 30.4s\n",
      "10:\tlearn: 1643.5955196\ttest: 1638.1570093\tbest: 1638.1570093 (10)\ttotal: 1.15s\tremaining: 30.3s\n",
      "11:\ttotal: 1.25s\tremaining: 30s\n",
      "12:\ttotal: 1.33s\tremaining: 29.4s\n",
      "13:\ttotal: 1.41s\tremaining: 28.9s\n",
      "14:\ttotal: 1.51s\tremaining: 28.8s\n",
      "15:\tlearn: 1564.6990187\ttest: 1559.6822430\tbest: 1559.6822430 (15)\ttotal: 1.62s\tremaining: 28.7s\n",
      "16:\ttotal: 1.69s\tremaining: 28.2s\n",
      "17:\ttotal: 1.8s\tremaining: 28.2s\n",
      "18:\ttotal: 1.9s\tremaining: 28.1s\n",
      "19:\ttotal: 2s\tremaining: 28s\n",
      "20:\tlearn: 1507.7006471\ttest: 1503.9233645\tbest: 1503.9233645 (20)\ttotal: 2.11s\tremaining: 28s\n",
      "21:\ttotal: 2.2s\tremaining: 27.8s\n",
      "22:\ttotal: 2.3s\tremaining: 27.7s\n",
      "23:\ttotal: 2.4s\tremaining: 27.7s\n",
      "24:\ttotal: 2.5s\tremaining: 27.5s\n",
      "25:\tlearn: 1465.1519846\ttest: 1461.5138488\tbest: 1461.5138488 (25)\ttotal: 2.6s\tremaining: 27.4s\n",
      "26:\ttotal: 2.68s\tremaining: 27.1s\n",
      "27:\ttotal: 2.78s\tremaining: 27s\n",
      "28:\ttotal: 2.88s\tremaining: 26.9s\n",
      "29:\ttotal: 2.98s\tremaining: 26.8s\n",
      "30:\tlearn: 1433.6957476\ttest: 1430.3918437\tbest: 1430.3918437 (30)\ttotal: 3.06s\tremaining: 26.6s\n",
      "31:\ttotal: 3.15s\tremaining: 26.4s\n",
      "32:\ttotal: 3.27s\tremaining: 26.4s\n",
      "33:\ttotal: 3.35s\tremaining: 26.2s\n",
      "34:\ttotal: 3.44s\tremaining: 26.1s\n",
      "35:\tlearn: 1403.5295884\ttest: 1400.4675446\tbest: 1400.4675446 (35)\ttotal: 3.55s\tremaining: 26s\n",
      "36:\ttotal: 3.63s\tremaining: 25.8s\n",
      "37:\ttotal: 3.72s\tremaining: 25.6s\n",
      "38:\ttotal: 3.82s\tremaining: 25.6s\n",
      "39:\ttotal: 3.9s\tremaining: 25.3s\n",
      "40:\tlearn: 1380.7141987\ttest: 1377.9671198\tbest: 1377.9671198 (40)\ttotal: 3.96s\tremaining: 25s\n",
      "41:\ttotal: 4.05s\tremaining: 24.9s\n",
      "42:\ttotal: 4.12s\tremaining: 24.6s\n",
      "43:\ttotal: 4.19s\tremaining: 24.4s\n",
      "44:\ttotal: 4.28s\tremaining: 24.3s\n",
      "45:\tlearn: 1361.1624067\ttest: 1358.5860663\tbest: 1358.5860663 (45)\ttotal: 4.37s\tremaining: 24.1s\n",
      "46:\ttotal: 4.46s\tremaining: 24s\n",
      "47:\ttotal: 4.55s\tremaining: 23.9s\n",
      "48:\ttotal: 4.64s\tremaining: 23.8s\n",
      "49:\ttotal: 4.74s\tremaining: 23.7s\n",
      "50:\tlearn: 1343.3688951\ttest: 1340.7825828\tbest: 1340.7825828 (50)\ttotal: 4.8s\tremaining: 23.5s\n",
      "51:\ttotal: 4.89s\tremaining: 23.3s\n",
      "52:\ttotal: 4.96s\tremaining: 23.1s\n",
      "53:\ttotal: 5.05s\tremaining: 23s\n",
      "54:\ttotal: 5.16s\tremaining: 23s\n",
      "55:\tlearn: 1328.3111910\ttest: 1325.7463891\tbest: 1325.7463891 (55)\ttotal: 5.28s\tremaining: 23s\n",
      "56:\ttotal: 5.35s\tremaining: 22.8s\n",
      "57:\ttotal: 5.42s\tremaining: 22.6s\n",
      "58:\ttotal: 5.51s\tremaining: 22.5s\n",
      "59:\ttotal: 5.59s\tremaining: 22.4s\n",
      "60:\tlearn: 1315.0279670\ttest: 1312.4774002\tbest: 1312.4774002 (60)\ttotal: 5.69s\tremaining: 22.3s\n",
      "61:\ttotal: 5.77s\tremaining: 22.2s\n",
      "62:\ttotal: 5.87s\tremaining: 22.1s\n",
      "63:\ttotal: 5.97s\tremaining: 22s\n",
      "64:\ttotal: 6.05s\tremaining: 21.9s\n",
      "65:\tlearn: 1304.2721081\ttest: 1302.2931181\tbest: 1302.2931181 (65)\ttotal: 6.14s\tremaining: 21.8s\n",
      "66:\ttotal: 6.23s\tremaining: 21.7s\n",
      "67:\ttotal: 6.34s\tremaining: 21.6s\n",
      "68:\ttotal: 6.42s\tremaining: 21.5s\n",
      "69:\ttotal: 6.52s\tremaining: 21.4s\n",
      "70:\tlearn: 1294.3372180\ttest: 1292.5095157\tbest: 1292.5095157 (70)\ttotal: 6.64s\tremaining: 21.4s\n",
      "71:\ttotal: 6.76s\tremaining: 21.4s\n",
      "72:\ttotal: 6.85s\tremaining: 21.3s\n",
      "73:\ttotal: 6.94s\tremaining: 21.2s\n",
      "74:\ttotal: 7.04s\tremaining: 21.1s\n",
      "75:\tlearn: 1285.7688724\ttest: 1284.1858114\tbest: 1284.1858114 (75)\ttotal: 7.1s\tremaining: 20.9s\n",
      "76:\ttotal: 7.17s\tremaining: 20.8s\n",
      "77:\ttotal: 7.24s\tremaining: 20.6s\n",
      "78:\ttotal: 7.32s\tremaining: 20.5s\n",
      "79:\ttotal: 7.41s\tremaining: 20.4s\n",
      "80:\tlearn: 1278.1047593\ttest: 1276.6117247\tbest: 1276.6117247 (80)\ttotal: 7.51s\tremaining: 20.3s\n",
      "81:\ttotal: 7.6s\tremaining: 20.2s\n",
      "82:\ttotal: 7.69s\tremaining: 20.1s\n",
      "83:\ttotal: 7.75s\tremaining: 19.9s\n",
      "84:\ttotal: 7.85s\tremaining: 19.9s\n",
      "85:\tlearn: 1272.6007448\ttest: 1271.4462192\tbest: 1271.4462192 (85)\ttotal: 7.93s\tremaining: 19.7s\n",
      "86:\ttotal: 8.04s\tremaining: 19.7s\n",
      "87:\ttotal: 8.14s\tremaining: 19.6s\n",
      "88:\ttotal: 8.24s\tremaining: 19.5s\n",
      "89:\ttotal: 8.3s\tremaining: 19.4s\n",
      "90:\tlearn: 1266.9707586\ttest: 1265.9423959\tbest: 1265.9423959 (90)\ttotal: 8.41s\tremaining: 19.3s\n",
      "91:\ttotal: 8.52s\tremaining: 19.3s\n",
      "92:\ttotal: 8.61s\tremaining: 19.2s\n",
      "93:\ttotal: 8.71s\tremaining: 19.1s\n",
      "94:\ttotal: 8.81s\tremaining: 19s\n",
      "95:\tlearn: 1262.2179300\ttest: 1261.4099405\tbest: 1261.4099405 (95)\ttotal: 8.88s\tremaining: 18.9s\n",
      "96:\ttotal: 8.98s\tremaining: 18.8s\n",
      "97:\ttotal: 9.08s\tremaining: 18.7s\n",
      "98:\ttotal: 9.16s\tremaining: 18.6s\n",
      "99:\ttotal: 9.27s\tremaining: 18.5s\n",
      "100:\tlearn: 1257.5705688\ttest: 1256.8153781\tbest: 1256.8153781 (100)\ttotal: 9.37s\tremaining: 18.5s\n",
      "101:\ttotal: 9.46s\tremaining: 18.4s\n",
      "102:\ttotal: 9.54s\tremaining: 18.2s\n",
      "103:\ttotal: 9.64s\tremaining: 18.2s\n",
      "104:\ttotal: 9.73s\tremaining: 18.1s\n",
      "105:\tlearn: 1254.0323709\ttest: 1253.3981308\tbest: 1253.3981308 (105)\ttotal: 9.82s\tremaining: 18s\n",
      "106:\ttotal: 9.9s\tremaining: 17.9s\n",
      "107:\ttotal: 9.98s\tremaining: 17.7s\n",
      "108:\ttotal: 10.1s\tremaining: 17.7s\n",
      "109:\ttotal: 10.2s\tremaining: 17.6s\n",
      "110:\tlearn: 1250.9870715\ttest: 1250.6129142\tbest: 1250.6129142 (110)\ttotal: 10.3s\tremaining: 17.5s\n",
      "111:\ttotal: 10.4s\tremaining: 17.4s\n",
      "112:\ttotal: 10.5s\tremaining: 17.3s\n",
      "113:\ttotal: 10.6s\tremaining: 17.2s\n",
      "114:\ttotal: 10.7s\tremaining: 17.1s\n",
      "115:\tlearn: 1246.6141973\ttest: 1246.5389125\tbest: 1246.5389125 (115)\ttotal: 10.8s\tremaining: 17.1s\n",
      "116:\ttotal: 10.9s\tremaining: 17s\n",
      "117:\ttotal: 10.9s\tremaining: 16.9s\n",
      "118:\ttotal: 11s\tremaining: 16.8s\n",
      "119:\ttotal: 11.1s\tremaining: 16.6s\n",
      "120:\tlearn: 1243.9686770\ttest: 1244.2289720\tbest: 1244.2289720 (120)\ttotal: 11.2s\tremaining: 16.6s\n",
      "121:\ttotal: 11.3s\tremaining: 16.5s\n",
      "122:\ttotal: 11.4s\tremaining: 16.4s\n",
      "123:\ttotal: 11.5s\tremaining: 16.3s\n",
      "124:\ttotal: 11.6s\tremaining: 16.2s\n",
      "125:\tlearn: 1241.7529560\ttest: 1242.2447749\tbest: 1242.2447749 (125)\ttotal: 11.7s\tremaining: 16.2s\n",
      "126:\ttotal: 11.8s\tremaining: 16.1s\n",
      "127:\ttotal: 11.9s\tremaining: 16s\n",
      "128:\ttotal: 12s\tremaining: 15.9s\n",
      "129:\ttotal: 12.1s\tremaining: 15.8s\n",
      "130:\tlearn: 1239.0352738\ttest: 1239.4892948\tbest: 1239.4892948 (130)\ttotal: 12.2s\tremaining: 15.7s\n",
      "131:\ttotal: 12.3s\tremaining: 15.6s\n",
      "132:\ttotal: 12.4s\tremaining: 15.5s\n",
      "133:\ttotal: 12.4s\tremaining: 15.4s\n",
      "134:\ttotal: 12.5s\tremaining: 15.3s\n",
      "135:\tlearn: 1236.7535083\ttest: 1237.4943076\tbest: 1237.4943076 (135)\ttotal: 12.6s\tremaining: 15.2s\n",
      "136:\ttotal: 12.7s\tremaining: 15.1s\n",
      "137:\ttotal: 12.8s\tremaining: 15s\n",
      "138:\ttotal: 12.9s\tremaining: 14.9s\n",
      "139:\ttotal: 13s\tremaining: 14.8s\n",
      "140:\tlearn: 1234.1192030\ttest: 1234.9448598\tbest: 1234.9448598 (140)\ttotal: 13.1s\tremaining: 14.7s\n",
      "141:\ttotal: 13.2s\tremaining: 14.6s\n",
      "142:\ttotal: 13.2s\tremaining: 14.5s\n",
      "143:\ttotal: 13.4s\tremaining: 14.5s\n",
      "144:\ttotal: 13.4s\tremaining: 14.4s\n",
      "145:\tlearn: 1232.2886475\ttest: 1233.2344095\tbest: 1233.2344095 (145)\ttotal: 13.5s\tremaining: 14.3s\n",
      "146:\ttotal: 13.6s\tremaining: 14.2s\n",
      "147:\ttotal: 13.7s\tremaining: 14.1s\n",
      "148:\ttotal: 13.8s\tremaining: 14s\n",
      "149:\ttotal: 13.9s\tremaining: 13.9s\n",
      "150:\tlearn: 1230.5347853\ttest: 1231.5193713\tbest: 1231.5193713 (150)\ttotal: 14s\tremaining: 13.8s\n",
      "151:\ttotal: 14.1s\tremaining: 13.7s\n",
      "152:\ttotal: 14.2s\tremaining: 13.6s\n",
      "153:\ttotal: 14.3s\tremaining: 13.6s\n",
      "154:\ttotal: 14.4s\tremaining: 13.5s\n",
      "155:\tlearn: 1227.9800054\ttest: 1229.1874257\tbest: 1229.1874257 (155)\ttotal: 14.5s\tremaining: 13.4s\n",
      "156:\ttotal: 14.6s\tremaining: 13.3s\n",
      "157:\ttotal: 14.7s\tremaining: 13.2s\n",
      "158:\ttotal: 14.8s\tremaining: 13.1s\n",
      "159:\ttotal: 14.9s\tremaining: 13s\n",
      "160:\tlearn: 1226.3211883\ttest: 1227.7604928\tbest: 1227.7604928 (160)\ttotal: 15s\tremaining: 12.9s\n",
      "161:\ttotal: 15.1s\tremaining: 12.8s\n",
      "162:\ttotal: 15.2s\tremaining: 12.7s\n",
      "163:\ttotal: 15.2s\tremaining: 12.6s\n",
      "164:\ttotal: 15.3s\tremaining: 12.5s\n",
      "165:\tlearn: 1224.3672666\ttest: 1226.1319456\tbest: 1226.1319456 (165)\ttotal: 15.4s\tremaining: 12.4s\n",
      "166:\ttotal: 15.5s\tremaining: 12.4s\n",
      "167:\ttotal: 15.6s\tremaining: 12.3s\n",
      "168:\ttotal: 15.7s\tremaining: 12.2s\n",
      "169:\ttotal: 15.8s\tremaining: 12.1s\n",
      "170:\tlearn: 1221.9758422\ttest: 1223.8152082\tbest: 1223.8152082 (170)\ttotal: 15.9s\tremaining: 12s\n",
      "171:\ttotal: 16s\tremaining: 11.9s\n",
      "172:\ttotal: 16.1s\tremaining: 11.8s\n",
      "173:\ttotal: 16.1s\tremaining: 11.7s\n",
      "174:\ttotal: 16.2s\tremaining: 11.6s\n",
      "175:\tlearn: 1220.8686048\ttest: 1222.7175871\tbest: 1222.7175871 (175)\ttotal: 16.3s\tremaining: 11.5s\n",
      "176:\ttotal: 16.4s\tremaining: 11.4s\n",
      "177:\ttotal: 16.5s\tremaining: 11.3s\n",
      "178:\ttotal: 16.6s\tremaining: 11.2s\n",
      "179:\ttotal: 16.7s\tremaining: 11.1s\n",
      "180:\tlearn: 1219.3074385\ttest: 1221.2729822\tbest: 1221.2729822 (180)\ttotal: 16.8s\tremaining: 11s\n",
      "181:\ttotal: 16.9s\tremaining: 10.9s\n",
      "182:\ttotal: 17s\tremaining: 10.9s\n",
      "183:\ttotal: 17.1s\tremaining: 10.8s\n",
      "184:\ttotal: 17.1s\tremaining: 10.6s\n",
      "185:\tlearn: 1217.9859811\ttest: 1219.9596432\tbest: 1219.9596432 (185)\ttotal: 17.2s\tremaining: 10.6s\n",
      "186:\ttotal: 17.3s\tremaining: 10.5s\n",
      "187:\ttotal: 17.4s\tremaining: 10.4s\n",
      "188:\ttotal: 17.5s\tremaining: 10.3s\n",
      "189:\ttotal: 17.6s\tremaining: 10.2s\n",
      "190:\tlearn: 1216.7079115\ttest: 1218.8724724\tbest: 1218.8724724 (190)\ttotal: 17.7s\tremaining: 10.1s\n",
      "191:\ttotal: 17.8s\tremaining: 10s\n",
      "192:\ttotal: 17.9s\tremaining: 9.91s\n",
      "193:\ttotal: 18s\tremaining: 9.82s\n",
      "194:\ttotal: 18.1s\tremaining: 9.73s\n",
      "195:\tlearn: 1215.4824056\ttest: 1217.9045879\tbest: 1217.9045879 (195)\ttotal: 18.2s\tremaining: 9.64s\n",
      "196:\ttotal: 18.3s\tremaining: 9.55s\n",
      "197:\ttotal: 18.3s\tremaining: 9.45s\n",
      "198:\ttotal: 18.4s\tremaining: 9.35s\n",
      "199:\ttotal: 18.5s\tremaining: 9.26s\n",
      "200:\tlearn: 1214.6020759\ttest: 1217.1717927\tbest: 1217.1717927 (200)\ttotal: 18.6s\tremaining: 9.16s\n",
      "201:\ttotal: 18.7s\tremaining: 9.06s\n",
      "202:\ttotal: 18.7s\tremaining: 8.96s\n",
      "203:\ttotal: 18.8s\tremaining: 8.87s\n",
      "204:\ttotal: 18.9s\tremaining: 8.77s\n",
      "205:\tlearn: 1213.9082117\ttest: 1216.6175021\tbest: 1216.6175021 (205)\ttotal: 19s\tremaining: 8.68s\n",
      "206:\ttotal: 19.1s\tremaining: 8.59s\n",
      "207:\ttotal: 19.2s\tremaining: 8.49s\n",
      "208:\ttotal: 19.3s\tremaining: 8.4s\n",
      "209:\ttotal: 19.4s\tremaining: 8.3s\n",
      "210:\tlearn: 1212.8768745\ttest: 1215.8932031\tbest: 1215.8932031 (210)\ttotal: 19.4s\tremaining: 8.2s\n",
      "211:\ttotal: 19.5s\tremaining: 8.11s\n",
      "212:\ttotal: 19.6s\tremaining: 8.01s\n",
      "213:\ttotal: 19.7s\tremaining: 7.92s\n",
      "214:\ttotal: 19.8s\tremaining: 7.83s\n",
      "215:\tlearn: 1211.8920970\ttest: 1215.0350042\tbest: 1215.0350042 (215)\ttotal: 19.9s\tremaining: 7.74s\n",
      "216:\ttotal: 20s\tremaining: 7.64s\n",
      "217:\ttotal: 20.1s\tremaining: 7.55s\n",
      "218:\ttotal: 20.2s\tremaining: 7.46s\n",
      "219:\ttotal: 20.3s\tremaining: 7.38s\n",
      "220:\tlearn: 1210.8153330\ttest: 1214.2114698\tbest: 1214.2114698 (220)\ttotal: 20.4s\tremaining: 7.28s\n",
      "221:\ttotal: 20.5s\tremaining: 7.2s\n",
      "222:\ttotal: 20.5s\tremaining: 7.09s\n",
      "223:\ttotal: 20.6s\tremaining: 7s\n",
      "224:\ttotal: 20.7s\tremaining: 6.91s\n",
      "225:\tlearn: 1209.8316884\ttest: 1213.4632965\tbest: 1213.4632965 (225)\ttotal: 20.8s\tremaining: 6.82s\n",
      "226:\ttotal: 20.9s\tremaining: 6.72s\n",
      "227:\ttotal: 20.9s\tremaining: 6.62s\n",
      "228:\ttotal: 21s\tremaining: 6.52s\n",
      "229:\ttotal: 21.1s\tremaining: 6.42s\n",
      "230:\tlearn: 1209.3034452\ttest: 1213.0848768\tbest: 1213.0848768 (230)\ttotal: 21.2s\tremaining: 6.33s\n",
      "231:\ttotal: 21.3s\tremaining: 6.24s\n",
      "232:\ttotal: 21.4s\tremaining: 6.16s\n",
      "233:\ttotal: 21.5s\tremaining: 6.06s\n",
      "234:\ttotal: 21.6s\tremaining: 5.96s\n",
      "235:\tlearn: 1208.5134029\ttest: 1212.4863212\tbest: 1212.4863212 (235)\ttotal: 21.6s\tremaining: 5.87s\n",
      "236:\ttotal: 21.7s\tremaining: 5.78s\n",
      "237:\ttotal: 21.8s\tremaining: 5.68s\n",
      "238:\ttotal: 21.9s\tremaining: 5.59s\n",
      "239:\ttotal: 22s\tremaining: 5.5s\n",
      "240:\tlearn: 1208.0560756\ttest: 1212.3108751\tbest: 1212.3108751 (240)\ttotal: 22.1s\tremaining: 5.4s\n",
      "241:\ttotal: 22.2s\tremaining: 5.31s\n",
      "242:\ttotal: 22.2s\tremaining: 5.21s\n",
      "243:\ttotal: 22.3s\tremaining: 5.12s\n",
      "244:\ttotal: 22.4s\tremaining: 5.03s\n",
      "245:\tlearn: 1207.4658661\ttest: 1211.8906542\tbest: 1211.8906542 (245)\ttotal: 22.5s\tremaining: 4.93s\n",
      "246:\ttotal: 22.6s\tremaining: 4.84s\n",
      "247:\ttotal: 22.6s\tremaining: 4.74s\n",
      "248:\ttotal: 22.7s\tremaining: 4.65s\n",
      "249:\ttotal: 22.8s\tremaining: 4.56s\n",
      "250:\tlearn: 1206.8394058\ttest: 1211.4752761\tbest: 1211.4752761 (250)\ttotal: 22.9s\tremaining: 4.47s\n",
      "251:\ttotal: 23s\tremaining: 4.38s\n",
      "252:\ttotal: 23.1s\tremaining: 4.29s\n",
      "253:\ttotal: 23.2s\tremaining: 4.2s\n",
      "254:\ttotal: 23.3s\tremaining: 4.11s\n",
      "255:\tlearn: 1206.0024639\ttest: 1210.8198811\tbest: 1210.8198811 (255)\ttotal: 23.4s\tremaining: 4.02s\n",
      "256:\ttotal: 23.5s\tremaining: 3.93s\n",
      "257:\ttotal: 23.6s\tremaining: 3.84s\n",
      "258:\ttotal: 23.6s\tremaining: 3.74s\n",
      "259:\ttotal: 23.7s\tremaining: 3.65s\n",
      "260:\tlearn: 1205.2737082\ttest: 1210.2603229\tbest: 1210.2603229 (260)\ttotal: 23.8s\tremaining: 3.56s\n",
      "261:\ttotal: 23.9s\tremaining: 3.47s\n",
      "262:\ttotal: 24s\tremaining: 3.38s\n",
      "263:\ttotal: 24.1s\tremaining: 3.28s\n",
      "264:\ttotal: 24.2s\tremaining: 3.19s\n",
      "265:\tlearn: 1204.7206559\ttest: 1209.7875956\tbest: 1209.7875956 (265)\ttotal: 24.3s\tremaining: 3.1s\n",
      "266:\ttotal: 24.3s\tremaining: 3.01s\n",
      "267:\ttotal: 24.4s\tremaining: 2.92s\n",
      "268:\ttotal: 24.5s\tremaining: 2.82s\n",
      "269:\ttotal: 24.6s\tremaining: 2.73s\n",
      "270:\tlearn: 1204.2284371\ttest: 1209.4446049\tbest: 1209.4446049 (270)\ttotal: 24.6s\tremaining: 2.64s\n",
      "271:\ttotal: 24.7s\tremaining: 2.55s\n",
      "272:\ttotal: 24.8s\tremaining: 2.46s\n",
      "273:\ttotal: 24.9s\tremaining: 2.36s\n",
      "274:\ttotal: 25s\tremaining: 2.27s\n",
      "275:\tlearn: 1203.5759215\ttest: 1208.9572642\tbest: 1208.9572642 (275)\ttotal: 25.1s\tremaining: 2.18s\n",
      "276:\ttotal: 25.2s\tremaining: 2.09s\n",
      "277:\ttotal: 25.3s\tremaining: 2s\n",
      "278:\ttotal: 25.4s\tremaining: 1.91s\n",
      "279:\ttotal: 25.5s\tremaining: 1.82s\n",
      "280:\tlearn: 1202.8391226\ttest: 1208.4145285\tbest: 1208.4145285 (280)\ttotal: 25.6s\tremaining: 1.73s\n",
      "281:\ttotal: 25.6s\tremaining: 1.64s\n",
      "282:\ttotal: 25.7s\tremaining: 1.55s\n",
      "283:\ttotal: 25.8s\tremaining: 1.46s\n",
      "284:\ttotal: 25.9s\tremaining: 1.36s\n",
      "285:\tlearn: 1202.0135091\ttest: 1207.8046729\tbest: 1207.8046729 (285)\ttotal: 26s\tremaining: 1.27s\n",
      "286:\ttotal: 26.1s\tremaining: 1.18s\n",
      "287:\ttotal: 26.2s\tremaining: 1.09s\n",
      "288:\ttotal: 26.3s\tremaining: 1s\n",
      "289:\ttotal: 26.4s\tremaining: 910ms\n",
      "290:\tlearn: 1201.5214036\ttest: 1207.5220051\tbest: 1207.5220051 (290)\ttotal: 26.5s\tremaining: 819ms\n",
      "291:\ttotal: 26.6s\tremaining: 728ms\n",
      "292:\ttotal: 26.7s\tremaining: 637ms\n",
      "293:\ttotal: 26.7s\tremaining: 546ms\n",
      "294:\ttotal: 26.8s\tremaining: 455ms\n",
      "295:\tlearn: 1200.7360059\ttest: 1206.9486831\tbest: 1206.9486831 (295)\ttotal: 26.9s\tremaining: 364ms\n",
      "296:\ttotal: 27s\tremaining: 273ms\n",
      "297:\ttotal: 27.1s\tremaining: 182ms\n",
      "298:\ttotal: 27.2s\tremaining: 91ms\n",
      "299:\tlearn: 1200.2947649\ttest: 1206.6614274\tbest: 1206.6614274 (299)\ttotal: 27.3s\tremaining: 0us\n",
      "bestTest = 1206.661427\n",
      "bestIteration = 299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x14cbf645a00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_model = CatBoostRegressor(iterations=300 , learning_rate=0.05 , max_depth=6 , eval_metric='MAE' , task_type='GPU' , random_state=42)\n",
    "catboost_model.fit(x_train , y_train , cat_features=np.asarray(cat_index)  , eval_set=(x_test , y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">test data accuracy with catboost model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error = 1206.6615223310732\n"
     ]
    }
   ],
   "source": [
    "y_pred = catboost_model.predict(x_test)\n",
    "print(f'mean_absolute_error = {mean_absolute_error(y_test , y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converte y to log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6474047\ttest: 0.6473399\tbest: 0.6473399 (0)\ttotal: 112ms\tremaining: 33.5s\n",
      "1:\ttotal: 207ms\tremaining: 30.8s\n",
      "2:\ttotal: 314ms\tremaining: 31.1s\n",
      "3:\ttotal: 415ms\tremaining: 30.7s\n",
      "4:\ttotal: 480ms\tremaining: 28.3s\n",
      "5:\tlearn: 0.5969259\ttest: 0.5969873\tbest: 0.5969873 (5)\ttotal: 601ms\tremaining: 29.4s\n",
      "6:\ttotal: 671ms\tremaining: 28.1s\n",
      "7:\ttotal: 756ms\tremaining: 27.6s\n",
      "8:\ttotal: 827ms\tremaining: 26.7s\n",
      "9:\ttotal: 920ms\tremaining: 26.7s\n",
      "10:\tlearn: 0.5605698\ttest: 0.5605869\tbest: 0.5605869 (10)\ttotal: 986ms\tremaining: 25.9s\n",
      "11:\ttotal: 1.07s\tremaining: 25.6s\n",
      "12:\ttotal: 1.15s\tremaining: 25.5s\n",
      "13:\ttotal: 1.26s\tremaining: 25.7s\n",
      "14:\ttotal: 1.34s\tremaining: 25.4s\n",
      "15:\tlearn: 0.5345847\ttest: 0.5346705\tbest: 0.5346705 (15)\ttotal: 1.45s\tremaining: 25.7s\n",
      "16:\ttotal: 1.51s\tremaining: 25.2s\n",
      "17:\ttotal: 1.57s\tremaining: 24.7s\n",
      "18:\ttotal: 1.67s\tremaining: 24.7s\n",
      "19:\ttotal: 1.77s\tremaining: 24.8s\n",
      "20:\tlearn: 0.5160519\ttest: 0.5162423\tbest: 0.5162423 (20)\ttotal: 1.87s\tremaining: 24.9s\n",
      "21:\ttotal: 1.96s\tremaining: 24.8s\n",
      "22:\ttotal: 2.07s\tremaining: 24.9s\n",
      "23:\ttotal: 2.17s\tremaining: 25s\n",
      "24:\ttotal: 2.26s\tremaining: 24.9s\n",
      "25:\tlearn: 0.5014829\ttest: 0.5016023\tbest: 0.5016023 (25)\ttotal: 2.37s\tremaining: 25s\n",
      "26:\ttotal: 2.46s\tremaining: 24.9s\n",
      "27:\ttotal: 2.52s\tremaining: 24.5s\n",
      "28:\ttotal: 2.63s\tremaining: 24.6s\n",
      "29:\ttotal: 2.72s\tremaining: 24.5s\n",
      "30:\tlearn: 0.4901091\ttest: 0.4901489\tbest: 0.4901489 (30)\ttotal: 2.82s\tremaining: 24.5s\n",
      "31:\ttotal: 2.93s\tremaining: 24.6s\n",
      "32:\ttotal: 3.03s\tremaining: 24.5s\n",
      "33:\ttotal: 3.13s\tremaining: 24.5s\n",
      "34:\ttotal: 3.23s\tremaining: 24.4s\n",
      "35:\tlearn: 0.4813154\ttest: 0.4813096\tbest: 0.4813096 (35)\ttotal: 3.33s\tremaining: 24.4s\n",
      "36:\ttotal: 3.43s\tremaining: 24.4s\n",
      "37:\ttotal: 3.52s\tremaining: 24.3s\n",
      "38:\ttotal: 3.62s\tremaining: 24.2s\n",
      "39:\ttotal: 3.7s\tremaining: 24.1s\n",
      "40:\tlearn: 0.4743744\ttest: 0.4744073\tbest: 0.4744073 (40)\ttotal: 3.79s\tremaining: 23.9s\n",
      "41:\ttotal: 3.88s\tremaining: 23.9s\n",
      "42:\ttotal: 3.96s\tremaining: 23.6s\n",
      "43:\ttotal: 4.06s\tremaining: 23.6s\n",
      "44:\ttotal: 4.16s\tremaining: 23.6s\n",
      "45:\tlearn: 0.4683788\ttest: 0.4682687\tbest: 0.4682687 (45)\ttotal: 4.27s\tremaining: 23.6s\n",
      "46:\ttotal: 4.37s\tremaining: 23.5s\n",
      "47:\ttotal: 4.47s\tremaining: 23.5s\n",
      "48:\ttotal: 4.55s\tremaining: 23.3s\n",
      "49:\ttotal: 4.64s\tremaining: 23.2s\n",
      "50:\tlearn: 0.4632806\ttest: 0.4630553\tbest: 0.4630553 (50)\ttotal: 4.74s\tremaining: 23.1s\n",
      "51:\ttotal: 4.84s\tremaining: 23.1s\n",
      "52:\ttotal: 4.92s\tremaining: 23s\n",
      "53:\ttotal: 5.02s\tremaining: 22.9s\n",
      "54:\ttotal: 5.12s\tremaining: 22.8s\n",
      "55:\tlearn: 0.4585004\ttest: 0.4581360\tbest: 0.4581360 (55)\ttotal: 5.22s\tremaining: 22.8s\n",
      "56:\ttotal: 5.32s\tremaining: 22.7s\n",
      "57:\ttotal: 5.43s\tremaining: 22.7s\n",
      "58:\ttotal: 5.53s\tremaining: 22.6s\n",
      "59:\ttotal: 5.63s\tremaining: 22.5s\n",
      "60:\tlearn: 0.4550387\ttest: 0.4546640\tbest: 0.4546640 (60)\ttotal: 5.73s\tremaining: 22.4s\n",
      "61:\ttotal: 5.81s\tremaining: 22.3s\n",
      "62:\ttotal: 5.92s\tremaining: 22.3s\n",
      "63:\ttotal: 6.04s\tremaining: 22.3s\n",
      "64:\ttotal: 6.15s\tremaining: 22.2s\n",
      "65:\tlearn: 0.4517796\ttest: 0.4513559\tbest: 0.4513559 (65)\ttotal: 6.25s\tremaining: 22.2s\n",
      "66:\ttotal: 6.35s\tremaining: 22.1s\n",
      "67:\ttotal: 6.46s\tremaining: 22.1s\n",
      "68:\ttotal: 6.57s\tremaining: 22s\n",
      "69:\ttotal: 6.67s\tremaining: 21.9s\n",
      "70:\tlearn: 0.4490551\ttest: 0.4486736\tbest: 0.4486736 (70)\ttotal: 6.78s\tremaining: 21.9s\n",
      "71:\ttotal: 6.91s\tremaining: 21.9s\n",
      "72:\ttotal: 7s\tremaining: 21.8s\n",
      "73:\ttotal: 7.1s\tremaining: 21.7s\n",
      "74:\ttotal: 7.2s\tremaining: 21.6s\n",
      "75:\tlearn: 0.4466385\ttest: 0.4461908\tbest: 0.4461908 (75)\ttotal: 7.28s\tremaining: 21.5s\n",
      "76:\ttotal: 7.39s\tremaining: 21.4s\n",
      "77:\ttotal: 7.47s\tremaining: 21.3s\n",
      "78:\ttotal: 7.57s\tremaining: 21.2s\n",
      "79:\ttotal: 7.66s\tremaining: 21.1s\n",
      "80:\tlearn: 0.4445645\ttest: 0.4441757\tbest: 0.4441757 (80)\ttotal: 7.78s\tremaining: 21s\n",
      "81:\ttotal: 7.88s\tremaining: 21s\n",
      "82:\ttotal: 7.99s\tremaining: 20.9s\n",
      "83:\ttotal: 8.09s\tremaining: 20.8s\n",
      "84:\ttotal: 8.2s\tremaining: 20.7s\n",
      "85:\tlearn: 0.4425981\ttest: 0.4422404\tbest: 0.4422404 (85)\ttotal: 8.29s\tremaining: 20.6s\n",
      "86:\ttotal: 8.4s\tremaining: 20.6s\n",
      "87:\ttotal: 8.49s\tremaining: 20.5s\n",
      "88:\ttotal: 8.58s\tremaining: 20.3s\n",
      "89:\ttotal: 8.7s\tremaining: 20.3s\n",
      "90:\tlearn: 0.4408124\ttest: 0.4404257\tbest: 0.4404257 (90)\ttotal: 8.8s\tremaining: 20.2s\n",
      "91:\ttotal: 8.9s\tremaining: 20.1s\n",
      "92:\ttotal: 9.01s\tremaining: 20s\n",
      "93:\ttotal: 9.1s\tremaining: 19.9s\n",
      "94:\ttotal: 9.2s\tremaining: 19.9s\n",
      "95:\tlearn: 0.4393487\ttest: 0.4390094\tbest: 0.4390094 (95)\ttotal: 9.31s\tremaining: 19.8s\n",
      "96:\ttotal: 9.39s\tremaining: 19.7s\n",
      "97:\ttotal: 9.48s\tremaining: 19.5s\n",
      "98:\ttotal: 9.59s\tremaining: 19.5s\n",
      "99:\ttotal: 9.69s\tremaining: 19.4s\n",
      "100:\tlearn: 0.4380790\ttest: 0.4377120\tbest: 0.4377120 (100)\ttotal: 9.79s\tremaining: 19.3s\n",
      "101:\ttotal: 9.88s\tremaining: 19.2s\n",
      "102:\ttotal: 9.99s\tremaining: 19.1s\n",
      "103:\ttotal: 10.1s\tremaining: 19s\n",
      "104:\ttotal: 10.2s\tremaining: 18.9s\n",
      "105:\tlearn: 0.4368423\ttest: 0.4364637\tbest: 0.4364637 (105)\ttotal: 10.3s\tremaining: 18.8s\n",
      "106:\ttotal: 10.4s\tremaining: 18.7s\n",
      "107:\ttotal: 10.5s\tremaining: 18.7s\n",
      "108:\ttotal: 10.6s\tremaining: 18.6s\n",
      "109:\ttotal: 10.7s\tremaining: 18.5s\n",
      "110:\tlearn: 0.4358484\ttest: 0.4354930\tbest: 0.4354930 (110)\ttotal: 10.8s\tremaining: 18.4s\n",
      "111:\ttotal: 10.9s\tremaining: 18.3s\n",
      "112:\ttotal: 11s\tremaining: 18.2s\n",
      "113:\ttotal: 11.1s\tremaining: 18s\n",
      "114:\ttotal: 11.1s\tremaining: 17.9s\n",
      "115:\tlearn: 0.4348188\ttest: 0.4344377\tbest: 0.4344377 (115)\ttotal: 11.2s\tremaining: 17.8s\n",
      "116:\ttotal: 11.3s\tremaining: 17.7s\n",
      "117:\ttotal: 11.4s\tremaining: 17.5s\n",
      "118:\ttotal: 11.4s\tremaining: 17.4s\n",
      "119:\ttotal: 11.6s\tremaining: 17.3s\n",
      "120:\tlearn: 0.4340546\ttest: 0.4336335\tbest: 0.4336335 (120)\ttotal: 11.7s\tremaining: 17.3s\n",
      "121:\ttotal: 11.8s\tremaining: 17.2s\n",
      "122:\ttotal: 11.9s\tremaining: 17.1s\n",
      "123:\ttotal: 11.9s\tremaining: 17s\n",
      "124:\ttotal: 12s\tremaining: 16.9s\n",
      "125:\tlearn: 0.4333446\ttest: 0.4329884\tbest: 0.4329884 (125)\ttotal: 12.1s\tremaining: 16.8s\n",
      "126:\ttotal: 12.3s\tremaining: 16.7s\n",
      "127:\ttotal: 12.4s\tremaining: 16.6s\n",
      "128:\ttotal: 12.5s\tremaining: 16.5s\n",
      "129:\ttotal: 12.6s\tremaining: 16.4s\n",
      "130:\tlearn: 0.4325633\ttest: 0.4322428\tbest: 0.4322428 (130)\ttotal: 12.7s\tremaining: 16.4s\n",
      "131:\ttotal: 12.8s\tremaining: 16.3s\n",
      "132:\ttotal: 12.9s\tremaining: 16.2s\n",
      "133:\ttotal: 13s\tremaining: 16.1s\n",
      "134:\ttotal: 13.1s\tremaining: 16s\n",
      "135:\tlearn: 0.4318537\ttest: 0.4315595\tbest: 0.4315595 (135)\ttotal: 13.2s\tremaining: 15.9s\n",
      "136:\ttotal: 13.3s\tremaining: 15.8s\n",
      "137:\ttotal: 13.4s\tremaining: 15.8s\n",
      "138:\ttotal: 13.5s\tremaining: 15.6s\n",
      "139:\ttotal: 13.6s\tremaining: 15.5s\n",
      "140:\tlearn: 0.4312838\ttest: 0.4310066\tbest: 0.4310066 (140)\ttotal: 13.7s\tremaining: 15.4s\n",
      "141:\ttotal: 13.8s\tremaining: 15.4s\n",
      "142:\ttotal: 13.9s\tremaining: 15.3s\n",
      "143:\ttotal: 14s\tremaining: 15.1s\n",
      "144:\ttotal: 14.1s\tremaining: 15s\n",
      "145:\tlearn: 0.4307215\ttest: 0.4304927\tbest: 0.4304927 (145)\ttotal: 14.2s\tremaining: 14.9s\n",
      "146:\ttotal: 14.2s\tremaining: 14.8s\n",
      "147:\ttotal: 14.3s\tremaining: 14.7s\n",
      "148:\ttotal: 14.4s\tremaining: 14.6s\n",
      "149:\ttotal: 14.6s\tremaining: 14.6s\n",
      "150:\tlearn: 0.4302243\ttest: 0.4300368\tbest: 0.4300368 (150)\ttotal: 14.7s\tremaining: 14.5s\n",
      "151:\ttotal: 14.8s\tremaining: 14.4s\n",
      "152:\ttotal: 14.9s\tremaining: 14.3s\n",
      "153:\ttotal: 15s\tremaining: 14.2s\n",
      "154:\ttotal: 15.1s\tremaining: 14.1s\n",
      "155:\tlearn: 0.4296337\ttest: 0.4294718\tbest: 0.4294718 (155)\ttotal: 15.2s\tremaining: 14s\n",
      "156:\ttotal: 15.2s\tremaining: 13.9s\n",
      "157:\ttotal: 15.3s\tremaining: 13.8s\n",
      "158:\ttotal: 15.4s\tremaining: 13.7s\n",
      "159:\ttotal: 15.5s\tremaining: 13.6s\n",
      "160:\tlearn: 0.4291001\ttest: 0.4289574\tbest: 0.4289574 (160)\ttotal: 15.6s\tremaining: 13.5s\n",
      "161:\ttotal: 15.7s\tremaining: 13.4s\n",
      "162:\ttotal: 15.8s\tremaining: 13.3s\n",
      "163:\ttotal: 15.9s\tremaining: 13.2s\n",
      "164:\ttotal: 16s\tremaining: 13.1s\n",
      "165:\tlearn: 0.4286718\ttest: 0.4285578\tbest: 0.4285578 (165)\ttotal: 16.1s\tremaining: 13s\n",
      "166:\ttotal: 16.2s\tremaining: 12.9s\n",
      "167:\ttotal: 16.3s\tremaining: 12.8s\n",
      "168:\ttotal: 16.4s\tremaining: 12.7s\n",
      "169:\ttotal: 16.4s\tremaining: 12.6s\n",
      "170:\tlearn: 0.4282315\ttest: 0.4281291\tbest: 0.4281291 (170)\ttotal: 16.5s\tremaining: 12.5s\n",
      "171:\ttotal: 16.6s\tremaining: 12.4s\n",
      "172:\ttotal: 16.7s\tremaining: 12.3s\n",
      "173:\ttotal: 16.8s\tremaining: 12.2s\n",
      "174:\ttotal: 16.9s\tremaining: 12.1s\n",
      "175:\tlearn: 0.4278152\ttest: 0.4277377\tbest: 0.4277377 (175)\ttotal: 17s\tremaining: 11.9s\n",
      "176:\ttotal: 17s\tremaining: 11.8s\n",
      "177:\ttotal: 17.1s\tremaining: 11.7s\n",
      "178:\ttotal: 17.2s\tremaining: 11.6s\n",
      "179:\ttotal: 17.3s\tremaining: 11.5s\n",
      "180:\tlearn: 0.4274374\ttest: 0.4273900\tbest: 0.4273900 (180)\ttotal: 17.4s\tremaining: 11.4s\n",
      "181:\ttotal: 17.5s\tremaining: 11.3s\n",
      "182:\ttotal: 17.6s\tremaining: 11.2s\n",
      "183:\ttotal: 17.7s\tremaining: 11.1s\n",
      "184:\ttotal: 17.8s\tremaining: 11s\n",
      "185:\tlearn: 0.4270392\ttest: 0.4270315\tbest: 0.4270315 (185)\ttotal: 17.9s\tremaining: 11s\n",
      "186:\ttotal: 18s\tremaining: 10.9s\n",
      "187:\ttotal: 18s\tremaining: 10.7s\n",
      "188:\ttotal: 18.1s\tremaining: 10.7s\n",
      "189:\ttotal: 18.2s\tremaining: 10.6s\n",
      "190:\tlearn: 0.4266324\ttest: 0.4266595\tbest: 0.4266595 (190)\ttotal: 18.3s\tremaining: 10.5s\n",
      "191:\ttotal: 18.4s\tremaining: 10.4s\n",
      "192:\ttotal: 18.5s\tremaining: 10.3s\n",
      "193:\ttotal: 18.6s\tremaining: 10.2s\n",
      "194:\ttotal: 18.7s\tremaining: 10.1s\n",
      "195:\tlearn: 0.4261428\ttest: 0.4262245\tbest: 0.4262245 (195)\ttotal: 18.8s\tremaining: 9.97s\n",
      "196:\ttotal: 18.9s\tremaining: 9.88s\n",
      "197:\ttotal: 19s\tremaining: 9.78s\n",
      "198:\ttotal: 19.1s\tremaining: 9.68s\n",
      "199:\ttotal: 19.2s\tremaining: 9.59s\n",
      "200:\tlearn: 0.4258529\ttest: 0.4259948\tbest: 0.4259948 (200)\ttotal: 19.3s\tremaining: 9.49s\n",
      "201:\ttotal: 19.4s\tremaining: 9.41s\n",
      "202:\ttotal: 19.5s\tremaining: 9.3s\n",
      "203:\ttotal: 19.6s\tremaining: 9.2s\n",
      "204:\ttotal: 19.6s\tremaining: 9.09s\n",
      "205:\tlearn: 0.4255677\ttest: 0.4257454\tbest: 0.4257454 (205)\ttotal: 19.7s\tremaining: 8.99s\n",
      "206:\ttotal: 19.8s\tremaining: 8.9s\n",
      "207:\ttotal: 19.9s\tremaining: 8.79s\n",
      "208:\ttotal: 20s\tremaining: 8.7s\n",
      "209:\ttotal: 20.1s\tremaining: 8.6s\n",
      "210:\tlearn: 0.4253471\ttest: 0.4255462\tbest: 0.4255462 (210)\ttotal: 20.1s\tremaining: 8.5s\n",
      "211:\ttotal: 20.3s\tremaining: 8.41s\n",
      "212:\ttotal: 20.4s\tremaining: 8.31s\n",
      "213:\ttotal: 20.4s\tremaining: 8.22s\n",
      "214:\ttotal: 20.5s\tremaining: 8.12s\n",
      "215:\tlearn: 0.4249876\ttest: 0.4252350\tbest: 0.4252350 (215)\ttotal: 20.6s\tremaining: 8.02s\n",
      "216:\ttotal: 20.7s\tremaining: 7.92s\n",
      "217:\ttotal: 20.8s\tremaining: 7.82s\n",
      "218:\ttotal: 20.9s\tremaining: 7.72s\n",
      "219:\ttotal: 21s\tremaining: 7.62s\n",
      "220:\tlearn: 0.4246874\ttest: 0.4249549\tbest: 0.4249549 (220)\ttotal: 21.1s\tremaining: 7.53s\n",
      "221:\ttotal: 21.2s\tremaining: 7.43s\n",
      "222:\ttotal: 21.3s\tremaining: 7.34s\n",
      "223:\ttotal: 21.3s\tremaining: 7.24s\n",
      "224:\ttotal: 21.4s\tremaining: 7.14s\n",
      "225:\tlearn: 0.4244069\ttest: 0.4247356\tbest: 0.4247356 (225)\ttotal: 21.5s\tremaining: 7.04s\n",
      "226:\ttotal: 21.6s\tremaining: 6.95s\n",
      "227:\ttotal: 21.7s\tremaining: 6.86s\n",
      "228:\ttotal: 21.8s\tremaining: 6.77s\n",
      "229:\ttotal: 21.9s\tremaining: 6.67s\n",
      "230:\tlearn: 0.4241318\ttest: 0.4245160\tbest: 0.4245160 (230)\ttotal: 22s\tremaining: 6.58s\n",
      "231:\ttotal: 22.1s\tremaining: 6.47s\n",
      "232:\ttotal: 22.2s\tremaining: 6.39s\n",
      "233:\ttotal: 22.3s\tremaining: 6.28s\n",
      "234:\ttotal: 22.4s\tremaining: 6.19s\n",
      "235:\tlearn: 0.4238397\ttest: 0.4242702\tbest: 0.4242702 (235)\ttotal: 22.5s\tremaining: 6.09s\n",
      "236:\ttotal: 22.6s\tremaining: 6s\n",
      "237:\ttotal: 22.7s\tremaining: 5.91s\n",
      "238:\ttotal: 22.8s\tremaining: 5.81s\n",
      "239:\ttotal: 22.9s\tremaining: 5.72s\n",
      "240:\tlearn: 0.4236189\ttest: 0.4240914\tbest: 0.4240914 (240)\ttotal: 23s\tremaining: 5.62s\n",
      "241:\ttotal: 23s\tremaining: 5.52s\n",
      "242:\ttotal: 23.1s\tremaining: 5.42s\n",
      "243:\ttotal: 23.2s\tremaining: 5.32s\n",
      "244:\ttotal: 23.3s\tremaining: 5.23s\n",
      "245:\tlearn: 0.4233823\ttest: 0.4238659\tbest: 0.4238659 (245)\ttotal: 23.4s\tremaining: 5.13s\n",
      "246:\ttotal: 23.5s\tremaining: 5.04s\n",
      "247:\ttotal: 23.6s\tremaining: 4.94s\n",
      "248:\ttotal: 23.6s\tremaining: 4.84s\n",
      "249:\ttotal: 23.7s\tremaining: 4.75s\n",
      "250:\tlearn: 0.4231555\ttest: 0.4236873\tbest: 0.4236873 (250)\ttotal: 23.8s\tremaining: 4.65s\n",
      "251:\ttotal: 23.9s\tremaining: 4.56s\n",
      "252:\ttotal: 24s\tremaining: 4.47s\n",
      "253:\ttotal: 24.2s\tremaining: 4.37s\n",
      "254:\ttotal: 24.3s\tremaining: 4.28s\n",
      "255:\tlearn: 0.4228647\ttest: 0.4234340\tbest: 0.4234340 (255)\ttotal: 24.4s\tremaining: 4.19s\n",
      "256:\ttotal: 24.5s\tremaining: 4.09s\n",
      "257:\ttotal: 24.6s\tremaining: 4s\n",
      "258:\ttotal: 24.7s\tremaining: 3.9s\n",
      "259:\ttotal: 24.8s\tremaining: 3.81s\n",
      "260:\tlearn: 0.4226281\ttest: 0.4232581\tbest: 0.4232581 (260)\ttotal: 24.9s\tremaining: 3.71s\n",
      "261:\ttotal: 25s\tremaining: 3.62s\n",
      "262:\ttotal: 25s\tremaining: 3.52s\n",
      "263:\ttotal: 25.1s\tremaining: 3.42s\n",
      "264:\ttotal: 25.2s\tremaining: 3.33s\n",
      "265:\tlearn: 0.4224125\ttest: 0.4231010\tbest: 0.4231010 (265)\ttotal: 25.3s\tremaining: 3.23s\n",
      "266:\ttotal: 25.4s\tremaining: 3.14s\n",
      "267:\ttotal: 25.4s\tremaining: 3.04s\n",
      "268:\ttotal: 25.5s\tremaining: 2.94s\n",
      "269:\ttotal: 25.7s\tremaining: 2.85s\n",
      "270:\tlearn: 0.4222369\ttest: 0.4229701\tbest: 0.4229701 (270)\ttotal: 25.7s\tremaining: 2.75s\n",
      "271:\ttotal: 25.8s\tremaining: 2.66s\n",
      "272:\ttotal: 25.9s\tremaining: 2.56s\n",
      "273:\ttotal: 26s\tremaining: 2.47s\n",
      "274:\ttotal: 26.1s\tremaining: 2.37s\n",
      "275:\tlearn: 0.4219853\ttest: 0.4227298\tbest: 0.4227298 (275)\ttotal: 26.2s\tremaining: 2.27s\n",
      "276:\ttotal: 26.3s\tremaining: 2.18s\n",
      "277:\ttotal: 26.3s\tremaining: 2.08s\n",
      "278:\ttotal: 26.4s\tremaining: 1.99s\n",
      "279:\ttotal: 26.5s\tremaining: 1.89s\n",
      "280:\tlearn: 0.4217801\ttest: 0.4225723\tbest: 0.4225723 (280)\ttotal: 26.6s\tremaining: 1.8s\n",
      "281:\ttotal: 26.7s\tremaining: 1.7s\n",
      "282:\ttotal: 26.8s\tremaining: 1.61s\n",
      "283:\ttotal: 26.9s\tremaining: 1.51s\n",
      "284:\ttotal: 27s\tremaining: 1.42s\n",
      "285:\tlearn: 0.4216098\ttest: 0.4224437\tbest: 0.4224437 (285)\ttotal: 27.1s\tremaining: 1.32s\n",
      "286:\ttotal: 27.2s\tremaining: 1.23s\n",
      "287:\ttotal: 27.3s\tremaining: 1.14s\n",
      "288:\ttotal: 27.3s\tremaining: 1.04s\n",
      "289:\ttotal: 27.4s\tremaining: 946ms\n",
      "290:\tlearn: 0.4214705\ttest: 0.4223610\tbest: 0.4223610 (290)\ttotal: 27.5s\tremaining: 851ms\n",
      "291:\ttotal: 27.6s\tremaining: 756ms\n",
      "292:\ttotal: 27.7s\tremaining: 662ms\n",
      "293:\ttotal: 27.8s\tremaining: 568ms\n",
      "294:\ttotal: 27.9s\tremaining: 473ms\n",
      "295:\tlearn: 0.4212665\ttest: 0.4221778\tbest: 0.4221778 (295)\ttotal: 28s\tremaining: 378ms\n",
      "296:\ttotal: 28.1s\tremaining: 284ms\n",
      "297:\ttotal: 28.2s\tremaining: 189ms\n",
      "298:\ttotal: 28.3s\tremaining: 94.7ms\n",
      "299:\tlearn: 0.4210872\ttest: 0.4220522\tbest: 0.4220522 (299)\ttotal: 28.4s\tremaining: 0us\n",
      "bestTest = 0.4220521835\n",
      "bestIteration = 299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x14c83256c70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_train.iloc[:,:-1]\n",
    "y = np.log(data_train.loss)\n",
    "x_train , x_test , y_train , y_test = train_test_split(X , y , random_state=42)\n",
    "catboost_model = CatBoostRegressor(iterations=300 , learning_rate=0.05 , max_depth=6 , eval_metric='MAE' , task_type='GPU' , random_state=42)\n",
    "catboost_model.fit(x_train , y_train , cat_features=np.asarray(cat_index) , eval_set=(x_test , y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">Train data accuracy with catboost model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5222304586280626\n"
     ]
    }
   ],
   "source": [
    "y_pred = catboost_model.predict(x_train)\n",
    "print(np.exp(mean_absolute_error(y_train , y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">test data accuracy with catboost model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_error = 1.5250882640126069\n"
     ]
    }
   ],
   "source": [
    "y_pred = catboost_model.predict(x_test)\n",
    "print(f'mean_absolute_error = {np.exp(mean_absolute_error(y_test , y_pred))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">save model for prediction new data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Catboost_Model_Insurance.txt' , 'wb') as file:\n",
    "    pickle.dump(catboost_model , file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
